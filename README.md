# langchain-phi3-huggingface-inference
Run Hugging Face's Phi-3 Mini model using LangChain in a Python project via VS Code. This project demonstrates prompt execution using langchain-huggingface and Inference API with token security via .env.
---
```markdown
# ğŸ§  LangChain + Phi-3 Mini (HuggingFace Inference)

This project demonstrates how to use [LangChain](https://python.langchain.com/) with Hugging Face's `microsoft/Phi-3-mini-4k-instruct` model via the Hugging Face Inference API. It's structured for secure and modular local development using Python.

---

## ğŸš€ Features

- âœ… Call Phi-3 Mini through HuggingFace Inference API using LangChain.
- âœ… Secure your API key with `.env` using `python-dotenv`.
- âœ… Lightweight and modular code for easy integration into future apps.
- âœ… Ideal for testing LLM prompts, building chains, or extending to agents.

---

## ğŸ§© Tech Stack

- **Python 3.10+**
- **LangChain 0.3.11**
- **Hugging Face Inference API**
- **HuggingFaceHub 0.26.5**
- **python-dotenv**

---

## ğŸ“ Folder Structure

```

langchain-phi3-mini-hf-inference/
â”œâ”€â”€ main.py               # Core logic to invoke GPT model
â”œâ”€â”€ .env                  # API token file (not committed)
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ README.md             # Project documentation

````

---

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/YourUsername/langchain-phi3-mini-hf-inference.git
cd langchain-phi3-mini-hf-inference
````

### 2ï¸âƒ£ Create & Activate Virtual Environment

```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Add Your API Key to `.env`

Create a `.env` file in the root directory:

```
HUGGINGFACEHUB_API_TOKEN=your_actual_token
```

ğŸ”— [Get your token here](https://huggingface.co/settings/tokens)

### 5ï¸âƒ£ Run the Script

```bash
python main.py
```

---

## ğŸ’¡ Example Output

```
Response from Phi-3:

â€¢ Generative AI refers to AI models that can create content such as text, images, and music.
â€¢ It uses deep learning techniques like transformers and large language models.
â€¢ Applications include chatbots, content generation, image synthesis, and more.
```

---

## ğŸ” Security Best Practices

Make sure `.env` is in your `.gitignore`:

```bash
.env
```

Never push your secret keys to GitHub.

---

## ğŸ“Œ Future Enhancements

* Integrate LangChain Prompt Templates
* Wrap with `LLMChain`
* Build a minimal Streamlit web app
* Add tools & memory to build autonomous agents

---

## ğŸ™Œ What I Learned

* How to use LangChain with Hugging Face-hosted models
* How to design secure API-based apps in Python
* Prompt formatting with LangChain's LLM wrappers
* Effective logging and API response handling
* Best practices for environment setup and modular code

---

## ğŸ§  Author

ğŸ‘¤ Govinda Tak
ğŸ“« Email: [govindatak19@gmail.com](mailto:govindatak19@gmail.com)
ğŸ”— GitHub: [GovindaTak](https://github.com/GovindaTak)

---

## ğŸ“œ License

Licensed under the MIT License.


